### **1. Ethical AI vs. Responsible AI**

- **Ethical AI**: Focuses on aligning AI systems with moral principles and societal values.
- **Responsible AI**: Extends beyond ethics to address real-world implications like bias, privacy, and fairness in AI systems.

### **2. Principles of Responsible AI**

- **Comprehensive**: Requires clear governance to prevent misuse and ensure accountability.
- **Explainable**: AI decisions and purpose must be easily understood by the general public.
- **Ethical**: Must eliminate bias and prevent harm.
- **Efficient**: AI systems should be sustainable, fast, and continually operational.

### **3. Examples of AI Ethics**

- **Lensa AI**: An app criticized for using artwork without consent or adequate compensation for artists.
- **ChatGPT**: Raises concerns about fairness when used inappropriately for tasks like contest-winning or essay writing.

### **4. Importance of AI Ethics**

- **Bias and Discrimination**: AI trained on biased data can harm marginalized groups.
- **Proactive Development**: Integrating ethical considerations during development is key to avoiding future problems.

### **5. Ethical Challenges of AI**

- **Bias**: Example of Amazon’s AI recruiting tool, which discriminated against women by downgrading resumes with “women” in them.
- **Privacy**: AI relies on vast amounts of data (often without consent), raising concerns about personal data misuse.
- **Environment**: Large AI models consume significant energy, prompting the need for environmentally responsible AI practices.

### **6. Creating Ethical AI**

- **Regulatory Frameworks**: Governments are implementing regulations to ensure AI benefits society and avoids legal/ethical harm.
- **Educational Resources**: Teaching the public about AI risks can help mitigate unethical behavior.

### **7. Human Rights Approach (UNESCO’s AI Principles)**

1. **Proportionality and Do No Harm**: AI should not exceed its legitimate aim, with risk assessments to prevent harm.
2. **Safety and Security**: Address safety and security risks.
3. **Privacy and Data Protection**: AI must protect privacy and be governed by strong data protection laws.
4. **Multi-stakeholder Governance**: Diverse stakeholder involvement ensures inclusive AI governance.
5. **Responsibility and Accountability**: AI systems should be auditable and traceable, ensuring accountability.
6. **Transparency and Explainability**: AI’s actions should be explainable to foster trust, with an appropriate balance between privacy and transparency.
7. **Human Oversight**: AI systems should not replace human responsibility and accountability.
8. **Sustainability**: AI must be evaluated against sustainability goals (e.g., UN’s Sustainable Development Goals).
9. **Awareness and Literacy**: Promote public understanding and digital literacy in AI.
10. **Fairness and Non-Discrimination**: AI systems must promote fairness, social justice, and inclusivity.

### **8. Case Study: Digi Yatra**

- **Digi Yatra**: A biometric boarding system in Indian airports, using facial recognition technology (FRT) to improve efficiency and security. The project highlights the need for responsible deployment of AI systems in public sectors, especially concerning privacy and safety.